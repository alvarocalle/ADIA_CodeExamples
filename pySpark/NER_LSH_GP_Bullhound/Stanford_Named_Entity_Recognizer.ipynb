{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/NER.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NER** (named-entity recognition) is the problem of identifying and classifying proper names in text, including locations, such as *China*; people, such as *George Bush*; and organizations, such as the *United Nations*. \n",
    "\n",
    "**Problem**: the NER task is, given a sentence, first to segment which words are part of entities, and then to classify each entity by type (person, organization, location, and so on). \n",
    "\n",
    "**Challenge**: many named entities are too rare to appear even in a large training set, and therefore the system must identify them based only on context. Also, identifying independent words is not a good approach: *New York* is a location but *New York Times* is an organization.\n",
    "\n",
    "**Solution**: linear chain Conditional Random Field (CRF) sequence models. \n",
    "\n",
    "\n",
    "More details here:\n",
    "\n",
    "- [StanfordNER](https://nlp.stanford.edu/software/CRF-NER.shtml).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso de uso:\n",
    "\n",
    "Dado un documento de texto queremos encontrar entidades que aparecen en ese texto (Personas y Organizaciones) e identificarlas en nuestra base de datos de nombres. Por ejemplo si en el documento aparece:\n",
    "\n",
    "- Lucia O'Keeffe,\n",
    "- O'Keeffe, Lucia,\n",
    "- Lucia Keeffe,\n",
    "- O'Keeffe, okeeffe, Keefe, O'Keffe, ..., \n",
    "\n",
    "el algoritmo debería identificarla una PERSONA llamada *Lucia O'Keeffe* que pertenece a *GP Bullhound*. Para ello no podemos hacer una comparación exacta entre las entidades encontradas por NER y la base de datos. La comparación la hacemos usando un algoritmo de [Fuzzy Name Matching](https://medium.com/bcggamma/an-ensemble-approach-to-large-scale-fuzzy-name-matching-b3e3fa124e3c)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/mmds.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import timezone\n",
    "\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests import Session\n",
    "\n",
    "import re\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "import unicodedata\n",
    "\n",
    "import json\n",
    "import urllib3\n",
    "\n",
    "# !pip install arango-python\n",
    "import arango\n",
    "from arango import ArangoClient\n",
    "from arango.response import Response\n",
    "from arango.http import HTTPClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import RegexTokenizer, NGram, HashingTF, MinHashLSH, CountVectorizer\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, LongType\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import wraps\n",
    "from time import time\n",
    "\n",
    "def timing(f):\n",
    "    @wraps(f)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start = time()\n",
    "        result = f(*args, **kwargs)\n",
    "        end = time()\n",
    "        print('Elapsed time: {}'.format(end-start))\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests import Session\n",
    "\n",
    "from arango.response import Response\n",
    "from arango.http import HTTPClient\n",
    "\n",
    "\n",
    "class CustomHTTPClient(HTTPClient):\n",
    "    \"\"\"My custom HTTP client with cool features.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._session = Session()\n",
    "        # Initialize your logger.\n",
    "        self._logger = logging.getLogger('my_logger')\n",
    "\n",
    "    def create_session(self, host):\n",
    "        session = Session()\n",
    "\n",
    "        # Add request header.\n",
    "        session.headers.update({'x-my-header': 'true'})\n",
    "\n",
    "        # Enable retries.\n",
    "        adapter = HTTPAdapter(max_retries=5)\n",
    "        self._session.mount('https://', adapter)\n",
    "\n",
    "        return session\n",
    "\n",
    "    def send_request(self,\n",
    "                     session,\n",
    "                     method,\n",
    "                     url,\n",
    "                     params=None,\n",
    "                     data=None,\n",
    "                     headers=None,\n",
    "                     auth=None):\n",
    "        # Add your own debug statement.\n",
    "        self._logger.debug('Sending request to {}'.format(url))\n",
    "\n",
    "        # Send a request.\n",
    "        response = session.request(\n",
    "            method=method,\n",
    "            url=url,\n",
    "            params=params,\n",
    "            data=data,\n",
    "            headers=headers,\n",
    "            auth=auth,\n",
    "            verify=False  # Disable SSL verification\n",
    "        )\n",
    "        self._logger.debug('Got {}'.format(response.status_code))\n",
    "\n",
    "        # Return an instance of arango.response.Response.\n",
    "        return Response(\n",
    "            method=response.request.method,\n",
    "            url=response.url,\n",
    "            headers=response.headers,\n",
    "            status_code=response.status_code,\n",
    "            status_text=response.reason,\n",
    "            raw_body=response.text,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timing\n",
    "def execute(query):\n",
    "    cursor = aql.execute(query)\n",
    "    item_keys = [doc for doc in cursor]\n",
    "    return item_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraccion de emails\n",
    "\n",
    "def textCleansing(text):\n",
    "    text = re.sub('[^A-Za-z0-9@ _.+-]+', ' ', text)\n",
    "    return str(text).replace('  ', ' ')\n",
    "\n",
    "def emailExtraction(text):\n",
    "    emails = list()    \n",
    "    pattern = \"([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)\"\n",
    "    return re.findall(pattern, text)\n",
    "    \n",
    "# text2 = textCleansing(text)\n",
    "# emails = emailExtraction(textCleansing(text2))\n",
    "# emails = list(dict.fromkeys(emails))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textNormalize(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub('[^a-zA-Z ]', '', str(text))\n",
    "    text = unicodedata.normalize('NFD', text)\n",
    "    return str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s-gltd\n",
      "commsflightglobal\n"
     ]
    }
   ],
   "source": [
    "def extractUrlMimecast(x):\n",
    "    x = str(x).replace('orgsMimecast/','')\n",
    "    url_body = x.split('.')\n",
    "    url_body = url_body[0:len(url_body)-1]\n",
    "    return ''.join(url_body)\n",
    "    \n",
    "print(extractUrlMimecast('orgsMimecast/s-gltd.com'))\n",
    "print(extractUrlMimecast('orgsMimecast/orgsMimecast/comms.flightglobal.com'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conexion a la BBDD. Descarga colecciones. Guardalas en CSV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "client = ArangoClient(hosts='https://localhost:XXX/', http_client=CustomHTTPClient())\n",
    "db = client.db('gp', username='root', password='kXaHdJJoKi')\n",
    "aql = db.aql\n",
    "pregel = db.pregel\n",
    "\n",
    "#-------------------------------------------------------------\n",
    "# PRUEBA DE CONEXION - Nº de documentos\n",
    "\n",
    "collection = 'peopleMaster'\n",
    "query=r'''RETURN LENGTH(''' + collection + ''')'''\n",
    "print(query)\n",
    "execute(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pd_documents.csv\t     pd_orgPipedrive.csv  pd_peopleExtraction.csv\r\n",
      "pd_documents_ner.csv\t     pd_orgsMaster.csv\t  pd_peopleMaster.csv\r\n",
      "pd_master_documents_ner.csv  pd_orgsMimecast.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls output/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### peopleMaster: colección con nombres de personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col = db.collection('peopleMaster')\n",
    "#pd_peopleMaster = pd.DataFrame(list(col))\n",
    "#pd_peopleMaster.to_csv('output/pd_peopleMaster.csv', index=False)\n",
    "pd_peopleMaster = pd.read_csv('output/pd_peopleMaster.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orgsMaster: colección con nombres de empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col = db.collection('orgsMaster')\n",
    "#pd_orgsMaster = pd.DataFrame(list(col))\n",
    "#pd_orgsMaster.to_csv('output/pd_orgsMaster.csv', index=False)\n",
    "pd_orgsMaster = pd.read_csv('output/pd_orgsMaster.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### peopleExtraction (no se necesita ya) -> info en peopleMaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col = db.collection('peopleExtraction')\n",
    "#pd_peopleExtraction = pd.DataFrame(list(col))\n",
    "#pd_peopleExtraction.to_csv('output/pd_peopleExtraction.csv', index=False)\n",
    "pd_peopleExtraction = pd.read_csv('output/pd_peopleExtraction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orgPipedrive (no se necesita ya) -> info en orgsMaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col = db.collection('orgPipedrive')\n",
    "#pd_orgPipedrive = pd.DataFrame(list(col))\n",
    "#pd_orgPipedrive.to_csv('output/pd_orgPipedrive.csv', index=False)\n",
    "pd_orgPipedrive = pd.read_csv('output/pd_orgPipedrive.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### orgMimecast (no se necesita ya) -> info en orgsMaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#col = db.collection('orgsMimecast')\n",
    "#pd_orgsMimecast = pd.DataFrame(list(col))\n",
    "#pd_orgsMimecast.to_csv('output/pd_orgsMimecast.csv', index=False)\n",
    "pd_orgMimecast = pd.read_csv('output/pd_orgsMimecast.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### master_documents_ner: colección con relaciones p1 $\\to$ p2 encontrado en d. Esta colección es el output del flujo de sparta de Yessica con NER en Java."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#col = db.collection('master_documents_ner')\n",
    "#pd_master_documents_ner = pd.DataFrame(list(col))\n",
    "#pd_master_documents_ner.to_csv('output/pd_master_documents_ner.csv', index=False)\n",
    "pd_master_documents_ner = pd.read_csv('output/pd_master_documents_ner.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### documents_ner: colección con las entidades encontradas por NER en Java."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#col = db.collection('documents_NER')\n",
    "#pd_documents_ner = pd.DataFrame(list(col))\n",
    "#pd_documents_ner.to_csv('output/pd_documents_ner.csv', index=False)\n",
    "pd_documents_ner = pd.read_csv('output/pd_documents_ner.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### documents: colección con los documentos a analizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection = 'documents'\n",
    "#query=r'''FOR d IN '''+collection+'''\n",
    "#  LIMIT 1000\n",
    "#  RETURN { key: d._key, text: d.text, uploader: d.uploaded_by, created: d.created_at, updated: d.updated_at }\n",
    "#'''\n",
    "#print(query)\n",
    "#col = execute(query)\n",
    "#pd_documents = pd.DataFrame(list(col))\n",
    "#pd_documents.to_csv('output/pd_documents.csv', index=False)\n",
    "pd_documents = pd.read_csv('output/pd_documents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_documents.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparamos el DataFrame con los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Personas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_peopleMaster</th>\n",
       "      <th>id_originally</th>\n",
       "      <th>name_nfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1571812576-132380815</td>\n",
       "      <td>peopleMimecast/ultano.kindelan@fyber.com</td>\n",
       "      <td>ultano kindelan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1571819599-55121593</td>\n",
       "      <td>peopleMimecast/info@cognitionx.io</td>\n",
       "      <td>charlie muirhead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1572879274-100347265</td>\n",
       "      <td>peopleMimecast/movie@youthsquare.hk</td>\n",
       "      <td>youth square</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       key_peopleMaster                             id_originally  \\\n",
       "0  1571812576-132380815  peopleMimecast/ultano.kindelan@fyber.com   \n",
       "5  1571819599-55121593   peopleMimecast/info@cognitionx.io          \n",
       "8  1572879274-100347265  peopleMimecast/movie@youthsquare.hk        \n",
       "\n",
       "           name_nfd  \n",
       "0  ultano kindelan   \n",
       "5  charlie muirhead  \n",
       "8  youth square      "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtro registros de la bbdd cuyo tipo es nombre\n",
    "pd_people = pd_peopleExtraction[pd_peopleExtraction.type == 'name']\n",
    "pd_people['name_nfd'] = pd_people.value.apply(lambda x: textNormalize(x))\n",
    "pd_people = pd_people[['key_peopleMaster','id_originally', 'name_nfd']]\n",
    "pd_people.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "305879\n",
      "197417\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_peopleMaster</th>\n",
       "      <th>name_nfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1571812576-132380815</td>\n",
       "      <td>ultano kindelan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1571819599-55121593</td>\n",
       "      <td>charlie muirhead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1572879274-100347265</td>\n",
       "      <td>youth square</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       key_peopleMaster          name_nfd\n",
       "0  1571812576-132380815  ultano kindelan \n",
       "5  1571819599-55121593   charlie muirhead\n",
       "8  1572879274-100347265  youth square    "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a quedarnos con las personas que tienen más de una palabra (nombre + apellido)\n",
    "\n",
    "pd_people_2 = pd_people[['key_peopleMaster', 'name_nfd']]\n",
    "pd_people_2.name_nfd = pd_people_2.name_nfd.apply(lambda x: x.strip())\n",
    "pd_people_2 = pd_people_2.drop_duplicates()\n",
    "pd_people_2 = pd_people_2[pd_people_2.name_nfd.str.contains(' ')]\n",
    "print(len(pd_people))\n",
    "print(len(pd_people_2))\n",
    "pd_people_2.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|key_peopleMaster    |name_nfd        |\n",
      "+--------------------+----------------+\n",
      "|1571812576-132380815|ultano kindelan |\n",
      "|1571819599-55121593 |charlie muirhead|\n",
      "+--------------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trabajamos en spark\n",
    "\n",
    "schema = StructType([StructField(\"key_peopleMaster\", StringType(), True),\n",
    "                     StructField(\"name_nfd\", StringType(), True)])\n",
    "df_people = spark.createDataFrame(pd_people_2, schema=schema)\n",
    "df_people.show(2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empresas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37459\n",
      "32858\n",
      "70317\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_originally</th>\n",
       "      <th>name</th>\n",
       "      <th>name_nfd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orgPipedrive/39497</td>\n",
       "      <td>RedMere Technology</td>\n",
       "      <td>redmere technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orgPipedrive/65382</td>\n",
       "      <td>Gestaweb 2020</td>\n",
       "      <td>gestaweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orgPipedrive/69002</td>\n",
       "      <td>Remy Valette</td>\n",
       "      <td>remy valette</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id_originally                name            name_nfd\n",
       "0  orgPipedrive/39497  RedMere Technology  redmere technology\n",
       "1  orgPipedrive/65382  Gestaweb 2020       gestaweb          \n",
       "2  orgPipedrive/69002  Remy Valette        remy valette      "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_orgPipedrive['name_nfd'] = pd_orgPipedrive.name.apply(lambda x: textNormalize(x))\n",
    "pd_orgPipedrive = pd_orgPipedrive[['_id','name','name_nfd']]\n",
    "pd_orgPipedrive.columns = ['id_originally', 'name', 'name_nfd']\n",
    "print(len(pd_orgPipedrive))\n",
    "# pd_orgPipedrive.head(3)\n",
    "\n",
    "pd_orgMimecast['name'] = pd_orgMimecast._id.apply(lambda x: extractUrlMimecast(x))\n",
    "pd_orgMimecast['name_nfd'] = pd_orgMimecast.name.apply(lambda x: textNormalize(x))\n",
    "pd_orgMimecast = pd_orgMimecast[['_id','name','name_nfd']]\n",
    "pd_orgMimecast.columns = ['id_originally', 'name', 'name_nfd']\n",
    "print(len(pd_orgMimecast))\n",
    "# pd_orgMimecast.head(3)\n",
    "\n",
    "pd_orgs = pd.concat([pd_orgPipedrive, pd_orgMimecast])\n",
    "print(len(pd_orgs))\n",
    "pd_orgs.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+\n",
      "|id_originally     |name              |name_nfd          |\n",
      "+------------------+------------------+------------------+\n",
      "|orgPipedrive/39497|RedMere Technology|redmere technology|\n",
      "|orgPipedrive/65382|Gestaweb 2020     |gestaweb          |\n",
      "+------------------+------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Trabajamos en spark\n",
    "\n",
    "schema = StructType([StructField(\"id_originally\", StringType(), True),\\\n",
    "                     StructField(\"name\", StringType(), True),\\\n",
    "                     StructField(\"name_nfd\", StringType(), True)])\n",
    "df_orgs = spark.createDataFrame(pd_orgs, schema=schema)\n",
    "df_orgs.show(2, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Busquedad de Entidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_entities2(entities):\n",
    "    \"\"\"\n",
    "    Gets dataframe output of StanfordNER tagger\n",
    "    and finds entities by looking at consecutive indices.\n",
    "    \n",
    "    input : entities - DataFrame with tagged words StanfordNER tagger (output)\n",
    "    output : list - entities (PERSON, ORGANIZATION)\n",
    "    \"\"\"\n",
    "\n",
    "    x = entities.index.values\n",
    "    L = []\n",
    "\n",
    "    i = 0\n",
    "    while i < len(x):\n",
    "        l = [x[i]]\n",
    "        j = i + 1\n",
    "        while (j < len(x)) and (x[j]-x[j-1]==1):\n",
    "            l.append(x[j])\n",
    "            j = j + 1\n",
    "        L.append(l)\n",
    "        i = j\n",
    "        \n",
    "    return [[' '.join(list(entities.loc[l, 'word'])), ' '.join(list(entities.loc[l, 'label'].unique()))] for l in L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#folder1 = '/home/eduardofernandez/Archivo/_INTELLIJ/2019_07_gpbullhound/eduardoner/src/main/resources/classifiers/'\n",
    "folder1 = '/home/acalle/Documentos/GP-bullhound/stanford-ner-2018-10-16/classifiers/'\n",
    "st = StanfordNERTagger(folder1+'english.all.3class.distsim.crf.ser.gz')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***********************************\n",
    "\n",
    "### Función: findEntityInText(text, orgsDF, peopleDF)\n",
    "\n",
    "***********************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findEntityInText(dict_text, df_orgs, df_people):\n",
    "    \"\"\"\n",
    "    Recibe un texto y encuentra entidades (empresas y personas) en ese texto. \n",
    "    Devuelve la ID del texto y las entidades encontradas.\n",
    "    \n",
    "    :param: - dict_text - diccionario {'key', 'text', 'uploaded_by', 'updated_at'}\n",
    "    :param: - df_orgs - SparkDF con información de organizaciones (orgPipedrive, orgMimecast)\n",
    "    :param: - df_people - SparkDF con información de personas (peopleExtraction)\n",
    "    \"\"\"\n",
    "\n",
    "    key = dict_text['key']\n",
    "    text = dict_text['text']\n",
    "    uploader = dict_text['uploader']\n",
    "    created = dict_text['created']    \n",
    "    updated = dict_text['updated']        \n",
    "    \n",
    "    if len(text)==0: \n",
    "        return [key, 'No text in document']\n",
    "    \n",
    "    #filter names with more than three characters:\n",
    "    df_orgs_2 = df_orgs.filter(F.length(F.col('name_nfd'))>3)\n",
    "    df_people_2 = df_people.filter(F.length(F.col('name_nfd'))>3)\n",
    "    \n",
    "    #NER entities\n",
    "    labelled = st.tag(text.split())\n",
    "    labelled = pd.DataFrame(labelled, columns=['word', 'label'])\n",
    "    entities = labelled[((labelled.label == 'PERSON') | (labelled.label == 'ORGANIZATION')) & (len(labelled.word)>1)]\n",
    "    entities = find_entities2(entities)\n",
    "    entities = pd.DataFrame(entities).drop_duplicates().reset_index(drop=True)\n",
    "    entities.columns = ['entity', 'type']\n",
    "\n",
    "    #spark df entities\n",
    "    schema = StructType([StructField(\"entity\", StringType(), True),\\\n",
    "                         StructField(\"type\", StringType(), True)])\n",
    "    df_entities = spark.createDataFrame(entities, schema=schema)\n",
    "    df_entities_2 = df_entities.withColumn('name_nfd', F.trim(F.lower(F.col('entity'))))\\\n",
    "                               .filter(F.length(F.col('name_nfd'))>3)\n",
    "        \n",
    "    # -----------------------\n",
    "    #fuzzy orgs vs. entities\n",
    "    # -----------------------   \n",
    "\n",
    "    #hashing model\n",
    "    model = Pipeline(stages=[\n",
    "        RegexTokenizer(pattern=\"\", inputCol=\"name_nfd\", outputCol=\"tokens\", minTokenLength=1),\n",
    "        NGram(n=3, inputCol=\"tokens\", outputCol=\"ngrams\"),\n",
    "        HashingTF(inputCol=\"ngrams\", outputCol=\"vectors\"),\n",
    "        MinHashLSH(inputCol=\"vectors\", outputCol=\"lsh\", numHashTables=5)\n",
    "    ])    \n",
    "    model = model.fit(df_orgs_2)    \n",
    "    df_orgs_hashed = model.transform(df_orgs_2)\n",
    "    df_entities_hashed = model.transform(df_entities_2)\n",
    "    \n",
    "    #similitud\n",
    "    threshold = 0.4\n",
    "    results_names = model.stages[-1]\\\n",
    "                     .approxSimilarityJoin(df_orgs_hashed, df_entities_hashed, threshold, distCol=\"dist_jaccard\")\\\n",
    "                     .select(\n",
    "                            F.col(\"datasetA.id_originally\"),\n",
    "                            F.col(\"datasetA.name\"),\n",
    "                            F.col(\"datasetB.entity\"),\n",
    "                            F.col(\"dist_jaccard\"))\n",
    "    pd_results1 = results_names.toPandas()    \n",
    "    \n",
    "    # -------------------------\n",
    "    #fuzzy people vs. entities\n",
    "    # -------------------------  \n",
    "    #hashing model\n",
    "    model = Pipeline(stages=[\n",
    "        RegexTokenizer(pattern=\"\", inputCol=\"name_nfd\", outputCol=\"tokens\", minTokenLength=1),\n",
    "        NGram(n=3, inputCol=\"tokens\", outputCol=\"ngrams\"),\n",
    "        HashingTF(inputCol=\"ngrams\", outputCol=\"vectors\"),\n",
    "        MinHashLSH(inputCol=\"vectors\", outputCol=\"lsh\", numHashTables=5)\n",
    "    ])    \n",
    "    model = model.fit(df_people_2)\n",
    "    df_people_hashed = model.transform(df_people_2)\n",
    "    df_entities_hashed = model.transform(df_entities_2)\n",
    "    \n",
    "    #similitud\n",
    "    threshold = 0.4\n",
    "    results_names = model.stages[-1]\\\n",
    "                     .approxSimilarityJoin(df_people_hashed, df_entities_hashed, threshold, distCol=\"dist_jaccard\")\\\n",
    "                     .select(\n",
    "                            F.col(\"datasetA.key_peopleMaster\"),\n",
    "                            F.col(\"datasetA.name_nfd\"),\n",
    "                            F.col(\"datasetB.entity\"),\n",
    "                            F.col(\"dist_jaccard\"))\n",
    "    pd_results2 = results_names.toPandas()\n",
    "    \n",
    "    return pd_results1, pd_results2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+\n",
      "|     id_originally|              name|          name_nfd|\n",
      "+------------------+------------------+------------------+\n",
      "|orgPipedrive/39497|RedMere Technology|redmere technology|\n",
      "|orgPipedrive/65382|     Gestaweb 2020|         gestaweb |\n",
      "+------------------+------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_orgs.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+\n",
      "|    key_peopleMaster|        name_nfd|\n",
      "+--------------------+----------------+\n",
      "|1571812576-132380815| ultano kindelan|\n",
      "| 1571819599-55121593|charlie muirhead|\n",
      "+--------------------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_people.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_text = dict(pd_documents.iloc[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_text['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_results1, pd_results2 = findEntityInText(dict_text, df_orgs, df_people)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_originally</th>\n",
       "      <th>name</th>\n",
       "      <th>entity</th>\n",
       "      <th>dist_jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orgsMimecast/avito.ru</td>\n",
       "      <td>avito</td>\n",
       "      <td>Avito</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orgPipedrive/38181</td>\n",
       "      <td>21 Ventures</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orgPipedrive/49244</td>\n",
       "      <td>Ayala Corporation</td>\n",
       "      <td>SINA Corporation</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orgPipedrive/40076</td>\n",
       "      <td>Investment AB Kinnevik</td>\n",
       "      <td>Investment AB Kinnevik</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orgsMimecast/e-tengelmann.de</td>\n",
       "      <td>e-tengelmann</td>\n",
       "      <td>Tengelmann</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>orgPipedrive/58120</td>\n",
       "      <td>Unica Corporation</td>\n",
       "      <td>SINA Corporation</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>orgPipedrive/72870</td>\n",
       "      <td>Rite Ventures</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>orgPipedrive/51605</td>\n",
       "      <td>HE Ventures</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>orgPipedrive/41662</td>\n",
       "      <td>Avito</td>\n",
       "      <td>Avito</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>orgPipedrive/39975</td>\n",
       "      <td>Granite Ventures</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>orgsMimecast/leboncoin.fr</td>\n",
       "      <td>leboncoin</td>\n",
       "      <td>LeBonCoin</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>orgsMimecast/tu-berlin.de</td>\n",
       "      <td>tu-berlin</td>\n",
       "      <td>BERLIN</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>orgPipedrive/74022</td>\n",
       "      <td>Intel</td>\n",
       "      <td>Intel</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>orgPipedrive/63903</td>\n",
       "      <td>Certona Corporation</td>\n",
       "      <td>SINA Corporation</td>\n",
       "      <td>0.368421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>orgsMimecast/fu-berlin.de</td>\n",
       "      <td>fu-berlin</td>\n",
       "      <td>BERLIN</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>orgPipedrive/74014</td>\n",
       "      <td>RWE ventures</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>orgPipedrive/53289</td>\n",
       "      <td>Mocana Corporation</td>\n",
       "      <td>SINA Corporation</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>orgPipedrive/74922</td>\n",
       "      <td>eBay Inc.</td>\n",
       "      <td>eBay Inc.</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>orgsMimecast/oberlin.edu</td>\n",
       "      <td>oberlin</td>\n",
       "      <td>BERLIN</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>orgPipedrive/45373</td>\n",
       "      <td>Phenomenon Ventures</td>\n",
       "      <td>Phenomen Ventures</td>\n",
       "      <td>0.176471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>orgsMimecast/mayfield.com</td>\n",
       "      <td>mayfield</td>\n",
       "      <td>Mayfield</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>orgsMimecast/intel.com</td>\n",
       "      <td>intel</td>\n",
       "      <td>Intel</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>orgPipedrive/74061</td>\n",
       "      <td>SoundCloud Ltd.</td>\n",
       "      <td>SoundCloud Ltd.</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>orgPipedrive/40076</td>\n",
       "      <td>Investment AB Kinnevik</td>\n",
       "      <td>Lamoda Investment AB Kinnevik</td>\n",
       "      <td>0.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>orgPipedrive/72969</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>orgsMimecast/soundcloud.com</td>\n",
       "      <td>soundcloud</td>\n",
       "      <td>SoundCloud Ltd.</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>orgPipedrive/37673</td>\n",
       "      <td>SoundCloud</td>\n",
       "      <td>SoundCloud Ltd.</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>orgsMimecast/vito.vc</td>\n",
       "      <td>vito</td>\n",
       "      <td>Avito</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>orgPipedrive/42473</td>\n",
       "      <td>Sanmina Corporation</td>\n",
       "      <td>SINA Corporation</td>\n",
       "      <td>0.277778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>orgsMimecast/mystubhub.com</td>\n",
       "      <td>mystubhub</td>\n",
       "      <td>StubHub</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>orgPipedrive/46089</td>\n",
       "      <td>Tencent Holdings Limited</td>\n",
       "      <td>Tencent Holdings Ltd.</td>\n",
       "      <td>0.360000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>orgPipedrive/42520</td>\n",
       "      <td>Elisa Corporation</td>\n",
       "      <td>SINA Corporation</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>orgPipedrive/73204</td>\n",
       "      <td>Goldman Sachs &amp; Co</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>orgsMimecast/avito.com</td>\n",
       "      <td>avito</td>\n",
       "      <td>Avito</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>orgPipedrive/68631</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>orgPipedrive/62003</td>\n",
       "      <td>TOM Group Limited</td>\n",
       "      <td>REA Group Limited</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>orgPipedrive/69160</td>\n",
       "      <td>StubHub</td>\n",
       "      <td>StubHub</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>orgPipedrive/49977</td>\n",
       "      <td>K/P Corporation</td>\n",
       "      <td>SINA Corporation</td>\n",
       "      <td>0.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>orgsMimecast/berling.fi</td>\n",
       "      <td>berling</td>\n",
       "      <td>BERLIN</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>orgPipedrive/38621</td>\n",
       "      <td>Mayfield</td>\n",
       "      <td>Mayfield</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>orgPipedrive/63543</td>\n",
       "      <td>.406 Ventures</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>orgPipedrive/68920</td>\n",
       "      <td>Dice Holdings, Inc.</td>\n",
       "      <td>Dice Holdings, Inc.</td>\n",
       "      <td>0.315789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>orgsMimecast/nk-berlin.de</td>\n",
       "      <td>nk-berlin</td>\n",
       "      <td>BERLIN</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>orgPipedrive/51794</td>\n",
       "      <td>Andreessen Horowitz</td>\n",
       "      <td>Andreessen Horowitz</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>orgPipedrive/38691</td>\n",
       "      <td>Casella Group Limited</td>\n",
       "      <td>REA Group Limited</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>orgPipedrive/58455</td>\n",
       "      <td>MBNA Corporation</td>\n",
       "      <td>SINA Corporation</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>orgsMimecast/goldmansachs.com</td>\n",
       "      <td>goldmansachs</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>orgsMimecast/berlin.de</td>\n",
       "      <td>berlin</td>\n",
       "      <td>BERLIN</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>orgPipedrive/69373</td>\n",
       "      <td>Goldman, Sachs &amp; Co.</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>orgPipedrive/56190</td>\n",
       "      <td>Phenomen Ventures</td>\n",
       "      <td>Phenomen Ventures</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>orgPipedrive/39648</td>\n",
       "      <td>RRE Ventures</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id_originally                      name  \\\n",
       "0   orgsMimecast/avito.ru          avito                      \n",
       "1   orgPipedrive/38181             21 Ventures                \n",
       "2   orgPipedrive/49244             Ayala Corporation          \n",
       "3   orgPipedrive/40076             Investment AB Kinnevik     \n",
       "4   orgsMimecast/e-tengelmann.de   e-tengelmann               \n",
       "5   orgPipedrive/58120             Unica Corporation          \n",
       "6   orgPipedrive/72870             Rite Ventures              \n",
       "7   orgPipedrive/51605             HE Ventures                \n",
       "8   orgPipedrive/41662             Avito                      \n",
       "9   orgPipedrive/39975             Granite Ventures           \n",
       "10  orgsMimecast/leboncoin.fr      leboncoin                  \n",
       "11  orgsMimecast/tu-berlin.de      tu-berlin                  \n",
       "12  orgPipedrive/74022             Intel                      \n",
       "13  orgPipedrive/63903             Certona Corporation        \n",
       "14  orgsMimecast/fu-berlin.de      fu-berlin                  \n",
       "15  orgPipedrive/74014             RWE ventures               \n",
       "16  orgPipedrive/53289             Mocana Corporation         \n",
       "17  orgPipedrive/74922             eBay Inc.                  \n",
       "18  orgsMimecast/oberlin.edu       oberlin                    \n",
       "19  orgPipedrive/45373             Phenomenon Ventures        \n",
       "20  orgsMimecast/mayfield.com      mayfield                   \n",
       "21  orgsMimecast/intel.com         intel                      \n",
       "22  orgPipedrive/74061             SoundCloud Ltd.            \n",
       "23  orgPipedrive/40076             Investment AB Kinnevik     \n",
       "24  orgPipedrive/72969             Goldman Sachs              \n",
       "25  orgsMimecast/soundcloud.com    soundcloud                 \n",
       "26  orgPipedrive/37673             SoundCloud                 \n",
       "27  orgsMimecast/vito.vc           vito                       \n",
       "28  orgPipedrive/42473             Sanmina Corporation        \n",
       "29  orgsMimecast/mystubhub.com     mystubhub                  \n",
       "30  orgPipedrive/46089             Tencent Holdings Limited   \n",
       "31  orgPipedrive/42520             Elisa Corporation          \n",
       "32  orgPipedrive/73204             Goldman Sachs & Co         \n",
       "33  orgsMimecast/avito.com         avito                      \n",
       "34  orgPipedrive/68631             Kite Ventures              \n",
       "35  orgPipedrive/62003             TOM Group Limited          \n",
       "36  orgPipedrive/69160             StubHub                    \n",
       "37  orgPipedrive/49977             K/P Corporation            \n",
       "38  orgsMimecast/berling.fi        berling                    \n",
       "39  orgPipedrive/38621             Mayfield                   \n",
       "40  orgPipedrive/63543             .406 Ventures              \n",
       "41  orgPipedrive/68920             Dice Holdings, Inc.        \n",
       "42  orgsMimecast/nk-berlin.de      nk-berlin                  \n",
       "43  orgPipedrive/51794             Andreessen Horowitz        \n",
       "44  orgPipedrive/38691             Casella Group Limited      \n",
       "45  orgPipedrive/58455             MBNA Corporation           \n",
       "46  orgsMimecast/goldmansachs.com  goldmansachs               \n",
       "47  orgsMimecast/berlin.de         berlin                     \n",
       "48  orgPipedrive/69373             Goldman, Sachs & Co.       \n",
       "49  orgPipedrive/56190             Phenomen Ventures          \n",
       "50  orgPipedrive/39648             RRE Ventures               \n",
       "\n",
       "                           entity  dist_jaccard  \n",
       "0   Avito                          0.000000      \n",
       "1   Kite Ventures                  0.363636      \n",
       "2   SINA Corporation               0.388889      \n",
       "3   Investment AB Kinnevik         0.000000      \n",
       "4   Tengelmann                     0.111111      \n",
       "5   SINA Corporation               0.388889      \n",
       "6   Kite Ventures                  0.166667      \n",
       "7   Kite Ventures                  0.333333      \n",
       "8   Avito                          0.000000      \n",
       "9   Kite Ventures                  0.333333      \n",
       "10  LeBonCoin                      0.000000      \n",
       "11  BERLIN                         0.333333      \n",
       "12  Intel                          0.000000      \n",
       "13  SINA Corporation               0.368421      \n",
       "14  BERLIN                         0.333333      \n",
       "15  Kite Ventures                  0.384615      \n",
       "16  SINA Corporation               0.333333      \n",
       "17  eBay Inc.                      0.142857      \n",
       "18  BERLIN                         0.200000      \n",
       "19  Phenomen Ventures              0.176471      \n",
       "20  Mayfield                       0.000000      \n",
       "21  Intel                          0.000000      \n",
       "22  SoundCloud Ltd.                0.076923      \n",
       "23  Lamoda Investment AB Kinnevik  0.259259      \n",
       "24  Goldman Sachs                  0.000000      \n",
       "25  SoundCloud Ltd.                0.384615      \n",
       "26  SoundCloud Ltd.                0.384615      \n",
       "27  Avito                          0.333333      \n",
       "28  SINA Corporation               0.277778      \n",
       "29  StubHub                        0.285714      \n",
       "30  Tencent Holdings Ltd.          0.360000      \n",
       "31  SINA Corporation               0.388889      \n",
       "32  Goldman Sachs                  0.266667      \n",
       "33  Avito                          0.000000      \n",
       "34  Kite Ventures                  0.000000      \n",
       "35  REA Group Limited              0.333333      \n",
       "36  StubHub                        0.000000      \n",
       "37  SINA Corporation               0.375000      \n",
       "38  BERLIN                         0.200000      \n",
       "39  Mayfield                       0.000000      \n",
       "40  Kite Ventures                  0.363636      \n",
       "41  Dice Holdings, Inc.            0.315789      \n",
       "42  BERLIN                         0.333333      \n",
       "43  Andreessen Horowitz            0.000000      \n",
       "44  REA Group Limited              0.380952      \n",
       "45  SINA Corporation               0.250000      \n",
       "46  Goldman Sachs                  0.384615      \n",
       "47  BERLIN                         0.000000      \n",
       "48  Goldman Sachs                  0.266667      \n",
       "49  Phenomen Ventures              0.000000      \n",
       "50  Kite Ventures                  0.384615      "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_results1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key_peopleMaster</th>\n",
       "      <th>name_nfd</th>\n",
       "      <th>entity</th>\n",
       "      <th>dist_jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1571761769-93155709</td>\n",
       "      <td>goldman sachs</td>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1571761769-85222693</td>\n",
       "      <td>tengelmann eday</td>\n",
       "      <td>Tengelmann</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1571828697-97525763</td>\n",
       "      <td>rse ventures</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1571813286-27934682</td>\n",
       "      <td>andreessen horowitz</td>\n",
       "      <td>Andreessen Horowitz</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1571943672-77086776</td>\n",
       "      <td>jme ventures</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1571828697-129553725</td>\n",
       "      <td>financial services</td>\n",
       "      <td>Financial Services Authority</td>\n",
       "      <td>0.384615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       key_peopleMaster             name_nfd                        entity  \\\n",
       "0  1571761769-93155709   goldman sachs        Goldman Sachs                  \n",
       "1  1571761769-85222693   tengelmann eday      Tengelmann                     \n",
       "2  1571828697-97525763   rse ventures         Kite Ventures                  \n",
       "3  1571813286-27934682   andreessen horowitz  Andreessen Horowitz            \n",
       "4  1571943672-77086776   jme ventures         Kite Ventures                  \n",
       "5  1571828697-129553725  financial services   Financial Services Authority   \n",
       "\n",
       "   dist_jaccard  \n",
       "0  0.000000      \n",
       "1  0.384615      \n",
       "2  0.384615      \n",
       "3  0.000000      \n",
       "4  0.384615      \n",
       "5  0.384615      "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_results2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ¿Qué hace la función por dentro?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = dict_text['key']\n",
    "text = dict_text['text']\n",
    "uploader = dict_text['uploader']\n",
    "created = dict_text['created']\n",
    "updated = dict_text['updated']        \n",
    "    \n",
    "#si no hay texto termina\n",
    "if len(text)==0: \n",
    "    print('No text in document')#return [key, 'No text in document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtra de nuestra BBDD nombres con mas de tres caracteres (NER se vuelve un poco loco)\n",
    "df_orgs_2 = df_orgs.filter(F.length(F.col('name_nfd'))>3)\n",
    "df_people_2 = df_people.filter(F.length(F.col('name_nfd'))>3)\n",
    "    \n",
    "#aplico NER\n",
    "labelled = st.tag(text.split())\n",
    "labelled = pd.DataFrame(labelled, columns=['word', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Valuation</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Analysis</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>November</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4688</th>\n",
       "      <td>FAX</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4689</th>\n",
       "      <td>+49(0)30</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4690</th>\n",
       "      <td>610</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4691</th>\n",
       "      <td>80</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4692</th>\n",
       "      <td>6029</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4693 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word label\n",
       "0     1          O   \n",
       "1     Valuation  O   \n",
       "2     Analysis   O   \n",
       "3     November   O   \n",
       "4     2012       O   \n",
       "...    ...      ..   \n",
       "4688  FAX        O   \n",
       "4689  +49(0)30   O   \n",
       "4690  610        O   \n",
       "4691  80         O   \n",
       "4692  6029       O   \n",
       "\n",
       "[4693 rows x 2 columns]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>APPENDIX</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>VALUATION</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SUMMARY</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>DCF</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>DCF</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4230</th>\n",
       "      <td>London</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4545</th>\n",
       "      <td>Financial</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4546</th>\n",
       "      <td>Services</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4547</th>\n",
       "      <td>Authority</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4675</th>\n",
       "      <td>BERLIN</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           word         label\n",
       "10    APPENDIX   ORGANIZATION\n",
       "12    VALUATION  ORGANIZATION\n",
       "13    SUMMARY    ORGANIZATION\n",
       "165   DCF        ORGANIZATION\n",
       "203   DCF        ORGANIZATION\n",
       "...   ...                 ...\n",
       "4230  London     ORGANIZATION\n",
       "4545  Financial  ORGANIZATION\n",
       "4546  Services   ORGANIZATION\n",
       "4547  Authority  ORGANIZATION\n",
       "4675  BERLIN     ORGANIZATION\n",
       "\n",
       "[250 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelled[labelled['label'].str.contains(\"PERSON|ORGANIZATION\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#python nltk no da entidades completas, por lo que usamos la funcion find_entities2\n",
    "entities = labelled[((labelled.label == 'PERSON') | (labelled.label == 'ORGANIZATION')) & (len(labelled.word)>1)]\n",
    "entities = find_entities2(entities)\n",
    "entities = pd.DataFrame(entities).drop_duplicates().reset_index(drop=True)\n",
    "entities.columns = ['entity', 'type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>APPENDIX</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VALUATION SUMMARY</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DCF</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EBITDA</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPS</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SoundCloud Ltd.</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Financial Services Authority</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>United Kingdom Financial Services Authority</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Jermyn Street, London</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>BERLIN</td>\n",
       "      <td>ORGANIZATION</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>68 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         entity          type\n",
       "0   APPENDIX                                     ORGANIZATION\n",
       "1   VALUATION SUMMARY                            ORGANIZATION\n",
       "2   DCF                                          ORGANIZATION\n",
       "3   EBITDA                                       ORGANIZATION\n",
       "4   PPS                                          ORGANIZATION\n",
       "..  ...                                                   ...\n",
       "63  SoundCloud Ltd.                              ORGANIZATION\n",
       "64  Financial Services Authority                 ORGANIZATION\n",
       "65  United Kingdom Financial Services Authority  ORGANIZATION\n",
       "66  Jermyn Street, London                        ORGANIZATION\n",
       "67  BERLIN                                       ORGANIZATION\n",
       "\n",
       "[68 rows x 2 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+\n",
      "|              entity|        type|            name_nfd|\n",
      "+--------------------+------------+--------------------+\n",
      "|            APPENDIX|ORGANIZATION|            appendix|\n",
      "|   VALUATION SUMMARY|ORGANIZATION|   valuation summary|\n",
      "|              EBITDA|ORGANIZATION|              ebitda|\n",
      "|               Avito|      PERSON|               avito|\n",
      "|    Avito IRR Slando|ORGANIZATION|    avito irr slando|\n",
      "|           LeBonCoin|ORGANIZATION|           leboncoin|\n",
      "|           eBay Inc.|ORGANIZATION|           ebay inc.|\n",
      "|   REA Group Limited|ORGANIZATION|   rea group limited|\n",
      "|SouFun Holdings Ltd.|ORGANIZATION|soufun holdings ltd.|\n",
      "|       Zillow , Inc.|ORGANIZATION|       zillow , inc.|\n",
      "| Dice Holdings, Inc.|ORGANIZATION| dice holdings, inc.|\n",
      "|JobStreet Corp. Bhd.|ORGANIZATION|jobstreet corp. bhd.|\n",
      "|         Yandex N.V.|ORGANIZATION|         yandex n.v.|\n",
      "|         Google Inc.|ORGANIZATION|         google inc.|\n",
      "|      Facebook, Inc.|ORGANIZATION|      facebook, inc.|\n",
      "|Tencent Holdings ...|ORGANIZATION|tencent holdings ...|\n",
      "|LinkedIn Corporation|ORGANIZATION|linkedin corporation|\n",
      "|Bankrate Apax Par...|ORGANIZATION|bankrate apax par...|\n",
      "|Zappos.com Amazon...|ORGANIZATION|zappos.com amazon...|\n",
      "|              Vatera|      PERSON|              vatera|\n",
      "+--------------------+------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#spark df_entities_2 -> contiene las entidades encontradas por NER\n",
    "schema = StructType([StructField(\"entity\", StringType(), True),\\\n",
    "                     StructField(\"type\", StringType(), True)])\n",
    "df_entities = spark.createDataFrame(entities, schema=schema)\n",
    "df_entities_2 = df_entities.withColumn('name_nfd', F.trim(F.lower(F.col('entity'))))\\\n",
    "                           .filter(F.length(F.col('name_nfd'))>3)\n",
    "df_entities_2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mining of Massive Datasets.** Jure Leskovec, Anand Rajaraman, Jeff Ullman\n",
    "\n",
    "**Minhashing** -> compress large documents into small signature matrices preserving the expected similarity of any pair of documents.\n",
    "\n",
    ">> _The probability that the minhash function for a random permutation of\n",
    "rows in a document matrix produces the same value for two sets equals the Jaccard similarity\n",
    "of those sets. The Jaccard similarities of the underlying sets are estimated from the signature matrix resulting of applying hash function._\n",
    "\n",
    "**Local-Sensitivity Hashing** -> focus only in the most similar pairs or all pairs that are above some lower bound in similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "#fuzzy orgs vs. entities\n",
    "# -----------------------   \n",
    "\n",
    "#hashing model -> Local Sensitive Hashing when comparing Big Datasets\n",
    "model = Pipeline(stages=[\n",
    "        RegexTokenizer(pattern=\"\", inputCol=\"name_nfd\", outputCol=\"tokens\", minTokenLength=1),\n",
    "        NGram(n=3, inputCol=\"tokens\", outputCol=\"ngrams\"),\n",
    "        HashingTF(inputCol=\"ngrams\", outputCol=\"vectors\"),\n",
    "        MinHashLSH(inputCol=\"vectors\", outputCol=\"lsh\", numHashTables=5)\n",
    "    ])    \n",
    "\n",
    "model = model.fit(df_orgs_2)    \n",
    "df_orgs_hashed = model.transform(df_orgs_2)\n",
    "df_entities_hashed = model.transform(df_entities_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|           entity|        type|         name_nfd|              tokens|              ngrams|             vectors|                 lsh|\n",
      "+-----------------+------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|         APPENDIX|ORGANIZATION|         appendix|[a, p, p, e, n, d...|[a p p, p p e, p ...|(262144,[30529,88...|[[2.47270919E8], ...|\n",
      "|VALUATION SUMMARY|ORGANIZATION|valuation summary|[v, a, l, u, a, t...|[v a l, a l u, l ...|(262144,[11798,50...|[[6.7059534E7], [...|\n",
      "|           EBITDA|ORGANIZATION|           ebitda|  [e, b, i, t, d, a]|[e b i, b i t, i ...|(262144,[33543,13...|[[3.94996328E8], ...|\n",
      "|            Avito|      PERSON|            avito|     [a, v, i, t, o]|[a v i, v i t, i ...|(262144,[201892,2...|[[1.036406121E9],...|\n",
      "| Avito IRR Slando|ORGANIZATION| avito irr slando|[a, v, i, t, o,  ...|[a v i, v i t, i ...|(262144,[22326,50...|[[4.64908172E8], ...|\n",
      "+-----------------+------------+-----------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_entities_hashed.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calcula la similitud\n",
    "threshold = 0.4\n",
    "results_names = model.stages[-1]\\\n",
    "                     .approxSimilarityJoin(df_orgs_hashed, df_entities_hashed, threshold, distCol=\"dist_jaccard\")\\\n",
    "                     .select(\n",
    "                            F.col(\"datasetA.id_originally\"),\n",
    "                            F.col(\"datasetA.name\"),\n",
    "                            F.col(\"datasetB.entity\"),\n",
    "                            F.col(\"dist_jaccard\"))\n",
    "pd_results1 = results_names.toPandas()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_originally</th>\n",
       "      <th>name</th>\n",
       "      <th>entity</th>\n",
       "      <th>dist_jaccard</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>orgsMimecast/avito.ru</td>\n",
       "      <td>avito</td>\n",
       "      <td>Avito</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orgPipedrive/38181</td>\n",
       "      <td>21 Ventures</td>\n",
       "      <td>Kite Ventures</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>orgPipedrive/49244</td>\n",
       "      <td>Ayala Corporation</td>\n",
       "      <td>SINA Corporation</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orgPipedrive/40076</td>\n",
       "      <td>Investment AB Kinnevik</td>\n",
       "      <td>Investment AB Kinnevik</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>orgsMimecast/e-tengelmann.de</td>\n",
       "      <td>e-tengelmann</td>\n",
       "      <td>Tengelmann</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id_originally                    name  \\\n",
       "0  orgsMimecast/avito.ru         avito                    \n",
       "1  orgPipedrive/38181            21 Ventures              \n",
       "2  orgPipedrive/49244            Ayala Corporation        \n",
       "3  orgPipedrive/40076            Investment AB Kinnevik   \n",
       "4  orgsMimecast/e-tengelmann.de  e-tengelmann             \n",
       "\n",
       "                   entity  dist_jaccard  \n",
       "0  Avito                   0.000000      \n",
       "1  Kite Ventures           0.363636      \n",
       "2  SINA Corporation        0.388889      \n",
       "3  Investment AB Kinnevik  0.000000      \n",
       "4  Tengelmann              0.111111      "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_results1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
